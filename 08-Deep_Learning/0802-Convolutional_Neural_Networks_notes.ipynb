{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "---\n",
    "\n",
    "A Convolutional Neural Network is an Artifical Neural Network focused on image classification.\n",
    "\n",
    "---\n",
    "\n",
    "## CNN Training\n",
    "\n",
    "### **STEP 1** - Convolution Operation:\n",
    "\n",
    "Convolution function:\n",
    "\n",
    "$$ (f * g)(t) = \\int^{\\infty}_{-\\infty} f(\\tau)g(t-\\tau) d\\tau $$\n",
    "\n",
    "Having an Input Image and a Feature Detector (also called Kernel or Filter), you can apply a convolution operation (represented with the $\\otimes$ symbol), and you will end up with a Feature Map.\n",
    "\n",
    "The convolution operation consists in mapping the product of each Feature Detector-sized section of the Input Image and the Feature Detector to a Feature Map. The product is obtained by multiplying the respective pixels in the section and the feature detector and adding the results for each sector. The more similar the sector is to the Feature Detector, the higher the product will be.\n",
    "\n",
    "We lose some information when we apply the Feature Detector, but at the same time we are helping the neural network to process the data faster, and at the same time we are focusing on where the common features are located on the image. The neural network will end up creating multiple feature maps and then the neural network will decide which ones are moe important.\n",
    "\n",
    "#### Different Filters\n",
    "\n",
    "##### Sharpen\n",
    "\n",
    "||||||\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|0|0|0|0|0|\n",
    "|0|0|-1|0|0|\n",
    "|0|-1|5|-1|0|\n",
    "|0|0|-1|0|0|\n",
    "|0|0|0|0|0|\n",
    "\n",
    "##### Blur\n",
    "\n",
    "||||||\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|0|0|0|0|0|\n",
    "|0|1|1|1|0|\n",
    "|0|1|1|1|0|\n",
    "|0|1|1|1|0|\n",
    "|0|0|0|0|0|\n",
    "\n",
    "##### Edge Enhance\n",
    "\n",
    "||||||\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|0|0|0|0|0|\n",
    "|0|0|0|0|0|\n",
    "|0|-1|1|0|0|\n",
    "|0|0|0|0|0|\n",
    "|0|0|0|0|0|\n",
    "\n",
    "##### Edge Detect\n",
    "\n",
    "||||||\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|0|0|0|0|0|\n",
    "|0|0|1|0|0|\n",
    "|0|1|-4|1|0|\n",
    "|0|0|1|0|0|\n",
    "|0|0|0|0|0|\n",
    "\n",
    "##### Emboss\n",
    "\n",
    "||||||\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|0|0|0|0|0|\n",
    "|0|-2|-1|0|0|\n",
    "|0|-2|1|1|0|\n",
    "|0|0|1|2|0|\n",
    "|0|0|0|0|0|\n",
    "\n",
    "#### **STEP 1(b)** - ReLU Layer:\n",
    "\n",
    "The ReLU function need to be applied after the convolutional operation to help reduce linearity in the model.\n",
    "\n",
    "### **STEP 2** - Pooling:\n",
    "\n",
    "As humans we don't have difficulties recognizing animals on different positions, or rotated; to help a CNN achieve that we use Max-Pooling. When we do Max-Pooling we are taking the max value from a \"pool\" of values on our feature map. Another reason we should use max pooling is because it reduces our image size, and our input variables.\n",
    "\n",
    "### **STEP 3** - Flattening:\n",
    "\n",
    "Flattening is taking our Pool Feature Map, and transform it into a column, to feed that to our CNN.\n",
    "\n",
    "### **STEP 4** - Full Connection:\n",
    "\n",
    "After flattening we create an Artificial Neural Network that will be feeded with the results of the previous steps. In this Neural Network all neurons are connected, that's the why the step is named \"Full Connection\".\n",
    "\n",
    "---\n",
    "\n",
    "## Softmax & Cross-Entropy\n",
    "\n",
    "### Softmax Function\n",
    "\n",
    "$$ f_{j}(z) = {e^{z_{j}} \\over \\sum_{k}{e^{z_{k}}}} $$\n",
    "\n",
    "The softmax function is a generalization of the logistic function that \"squashes\" a k-dimensional vector of arbitrary real values to a k-dimensional vector of real values in the range of 0-1 that all add up to 1.\n",
    "\n",
    "### Cross-Entropy Function\n",
    "\n",
    "Real Function:\n",
    "\n",
    "$$ L_{i} = -log({e^{f_{y_{i}}} \\over \\sum_{j} e^{f_{j}}}) $$\n",
    "\n",
    "Other representation (?):\n",
    "\n",
    "$$ H(p, q) = -\\sum_{x} p(x) \\cdot log(q(x)) $$\n",
    "\n",
    "We want to minimize the loss function to maximize the network's performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Reading\n",
    "\n",
    "*Introduction to Convolutional Neural Networks*. By Jianxin Wu (2017). Link: http://cs.nju.edu.cn/wujx/paper/CNN.pdf.\n",
    "\n",
    "*Understanding Convolutional Neural Networks with A Mathematical Model*. By C.-C. Jay Kuo (2016). Link: https://arxiv.org/pdf/1609.04112.pdf.\n",
    "\n",
    "*Delving Deep into Rectifiers: Surprassing Human-Level Performance on ImageNet Classification*. By Kaimin He et al. (2015). Link: https://arxiv.org/pdf/1502.01852.pdf.\n",
    "\n",
    "*Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition*. By Dominik Scherer et al. (2010). Link: https://ais.uni-bonn.de/papers/icann2010_maxpool.pdf.\n",
    "\n",
    "*The 9 Deep Learning Papers You Need To Know About (Understanding CNNs Part 3)*. Adit Deshpande (2016). Link: https://adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html.\n",
    "\n",
    "*A Friendly Introduction to Croo-Entropy Loss*. By Rob DiPietro (2016). Link: https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/.\n",
    "\n",
    "*Softmax classification with cross-entropy (2/2)*. By Peter Roelants (2015). Link: https://peterroelants.github.io/posts/cross-entropy-softmax/.\n",
    "\n",
    "<s>*Gradient-Based Learning Applied to Document recognition*. By Yann LeCun et al. (1998). Link: http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf.</s>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-venv-py3-11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
