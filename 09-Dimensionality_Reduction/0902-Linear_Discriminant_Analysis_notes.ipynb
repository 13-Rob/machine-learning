{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis (LDA)\n",
    "\n",
    "---\n",
    "\n",
    "## LDA & PCA\n",
    "\n",
    "LDA is commonly used as a dimensionality reduction technique, in the pre-processing step for pattern classification, and has the goal to project a dataset onto a lower-dimensional space, just like PCA. What makes LDA different from PCA is that LDA is interested in the axes that maximize the separation between multiple classes.\n",
    "\n",
    "---\n",
    "\n",
    "## Goal\n",
    "\n",
    "Project a feature space (a dataset $n$-dimensional samples) onto a small subspace $k$ (where $k \\le n-1$) while maintaining the class-discriminatory information.\n",
    "\n",
    "Both PCA and LDA are linear transformation techniques used for dimensional reduction. PCA is described as *unsupervised* but LDA is *supervised* because of the relation to the dependent variable.\n",
    "\n",
    "---\n",
    "\n",
    "## LDA Algorithm\n",
    "\n",
    "**STEP 1**: Compute the $d$-dimensional mean vectors for the different classes from the dataset.\n",
    "\n",
    "**STEP 2**: Compute the scatter matrices (in-between-class and within-class scatter matrix).\n",
    "\n",
    "**STEP 3**: Compute the eigenvectors ($e_{1}, e_{2}, ..., e_{d}$) and corresponding eigenvalues ($\\lambda_{1}, \\lambda_{2}, ..., \\lambda_{d}$) for the scatter matrices.\n",
    "\n",
    "**STEP 4**: Sort the eigenvectors by decreasing eigenvalues and choose $k$ eigenvectors with the largest eigenvalues to form a $d \\times k$ dimensional matrix **$W$** (where every columnm represents an eigenvector).\n",
    "\n",
    "**STEP 5**: Use this $d \\times k$ eigenvector matrix to transform the samples onto the new subspace. This can be summarized by the matrix multiplication: **$Y = X \\times W$** (where **$X$** is an $n \\times d$-dimensional matrix representing the **$n$** samples, and **$y$** are the tranformed $n \\times k$-dimensional samples in the new subspace).\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Reading\n",
    "\n",
    "https://sebastianraschka.com/publications/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
