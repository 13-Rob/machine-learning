{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering\n",
    "\n",
    "---\n",
    "\n",
    "The first step to create clusters using this method is to decide how many clisters of data you want. For each class there has to be a randomly placed centroid. After that, the next thing to do is calculate the center of mass of our cluster, excluding the centroids. Then we move the centroids to the center of mass location, reassign the data point to the closest centroid, and repeat the process.\n",
    "\n",
    "---\n",
    "\n",
    "## The Elbow Method\n",
    "\n",
    "### Within Cluster Sum of Squares:\n",
    "\n",
    "$$ WCSS = \\sum_{P_{i} in Cluster 1} distance (P_{i}, C_{1})^2 + \\sum_{P_{i} in Cluster 2} distance (P_{i}, C_{2})^2 + ... $$\n",
    "\n",
    "We calculate the WCSS for different Numbers of Clusters and see where the WCSS stops dropping rapidly, that's the number of clusters we will choose.\n",
    "\n",
    "---\n",
    "\n",
    "## K-Means++\n",
    "\n",
    "The K-Means++ helps you to lower the chances of fallig into the random initialization trap.\n",
    "\n",
    "**STEP 1**: Choose first centroid at random among data points.\n",
    "\n",
    "**STEP 2**: For each of the remaining data points compute the distance ($D$) to the nearest out of already selected centroids.\n",
    "\n",
    "**STEP 3**: Choose next centroid among remaining data points using weighted random selection - weighted by $D^{s}$\n",
    "\n",
    "**STEP 4**: Repeat STEPS 2 & 3 until all $k$ centroids have been selected.\n",
    "\n",
    "**STEP 5**: Proceed with standard k-means clustering.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
